import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics import silhouette_score
from sklearn.model_selection import ParameterGrid
from scipy.spatial.transform import Rotation
import time
import serial
import json
import matplotlib.pyplot as plt

# Config
COLLECTION_DURATION_T = 30
NUM_FRAMES_N = 10
start_time = time.time()
VOXEL_GRID_SIZE = 50.0 
WORK_ENVIRONMENT_SIZE = np.array([1500, 1400, 1600])
VOXEL_MATRIX_SHAPE = (WORK_ENVIRONMENT_SIZE / VOXEL_GRID_SIZE).astype(int)
TIME_TOLERANCE = 1.0
STATIC_HIT_THRESHOLD = 100 

# Sensor Setup
sensor_positions = np.array([
    [760.0, 700.0, 800], [737.410, 653.092, 800], [686.650, 641.506, 800],
    [645.946, 673.966, 800],[645.946, 726.034, 800], [686.650, 758.494, 800],
    [737.410, 746.908, 800],
])
sensor_rotation = np.array([
    [0.0, 0.0, 0.0], [0.0, 0.0, 308.57], [0.0, 0.0, 257.14],
    [0.0, 0.0, 205.71], [0.0, 0.0, 154.29], [0.0, 0.0, 102.86],
    [0.0, 0.0, 51.43],
])
ALL_SENSOR_ROTATION = np.array([[0.0, 0.0, 45.0]])
for i in range(len(sensor_rotation)):
    sensor_rotation[i] = sensor_rotation[i] + ALL_SENSOR_ROTATION
SENSOR_MATRIX_WIDTH = 8

# Voxel Grids
voxel_matrix = np.zeros(VOXEL_MATRIX_SHAPE, dtype=np.float64)
static_voxel_matrix = np.zeros(VOXEL_MATRIX_SHAPE, dtype=np.uint32)


def get_voxel_coordinates(real_coordinate):
    voxel_coordinate = np.round(real_coordinate / VOXEL_GRID_SIZE)
    return voxel_coordinate.astype(int)

def get_sensor_rot(sensor_id):
    angles = sensor_rotation[sensor_id]
    return Rotation.from_euler('xyz', angles, degrees=True)

def get_active_voxel_indices(time_now):
    indices = np.where((time_now - voxel_matrix) < TIME_TOLERANCE)
    return np.column_stack(indices).astype(int)

def is_valid_point(check_point):
    return all(0 <= int(coord) < int(max_dim) for coord, max_dim in zip(check_point, VOXEL_MATRIX_SHAPE))

def add_measurement(measured_real_coordinates, measurement_time):
    measured_voxel_coordinates = get_voxel_coordinates(measured_real_coordinates)
    for coordinate in measured_voxel_coordinates:
        if is_valid_point(coordinate):
            coord_tuple = tuple(coordinate)
            voxel_matrix[coord_tuple] = measurement_time
            if static_voxel_matrix[coord_tuple] < STATIC_HIT_THRESHOLD:
                static_voxel_matrix[coord_tuple] += 1

def read_json(json_input, time_now, serial_connection):
    SENSORS_ON_RING = 7
    try:
        json_data = json.loads(json_input)
    except json.JSONDecodeError:
        if serial_connection:
            serial_connection.reset_input_buffer()
        return

    if not isinstance(json_data, dict):
        return

    for sensor_id in range(SENSORS_ON_RING):
        sensor_name = f"sensor{sensor_id}"
        if sensor_name not in json_data: continue
        distance_array = np.array([item[0] for item in json_data[sensor_name]])
        distance_matrix = distance_array.reshape((SENSOR_MATRIX_WIDTH, SENSOR_MATRIX_WIDTH))
        valid_mask = distance_matrix.flatten() > 0
        if not np.any(valid_mask): continue
        x, y, z = sensor_positions[sensor_id]
        rot = get_sensor_rot(sensor_id)
        i, j = np.meshgrid(np.arange(SENSOR_MATRIX_WIDTH), np.arange(SENSOR_MATRIX_WIDTH), indexing='ij')
        koo_x = np.tan(np.radians(60.0 / 7.0 * i - 30.0)) * distance_matrix
        koo_y = distance_matrix
        koo_z = np.tan(np.radians(30.0 - 60.0 / 7.0 * j)) * distance_matrix
        all_points = np.stack([koo_x, koo_y, koo_z], axis=-1)
        valid_points = all_points.reshape(-1, 3)[valid_mask]
        transformed_points = rot.apply(valid_points) + np.array([x, y, z])
        add_measurement(transformed_points, time_now)


def run_optimization():
    print(f"Starting data collection for {COLLECTION_DURATION_T} seconds...")
    
    try:
        serial_connection = serial.Serial(port='COM3', baudrate=460800, timeout=1) # port may vary
    except serial.SerialException as e:
        print(f"Could not open COM-Port: {e}")
        return

    collected_frames = []
    collection_end_time = time.time() + COLLECTION_DURATION_T
    interval = COLLECTION_DURATION_T / NUM_FRAMES_N
    next_capture_time = time.time() + interval

    while time.time() < collection_end_time:
        time_now = time.time()
        new_raw_line = serial_connection.readline().decode('utf-8').rstrip()
        
        if not new_raw_line:
            time.sleep(0.001)
            continue
            
        read_json(new_raw_line, time_now, serial_connection)
        
        if time.time() >= next_capture_time:
            print(f"...Frame {len(collected_frames) + 1}/{NUM_FRAMES_N} at t={time_now - start_time:.1f}s collected")
            
            all_active_voxel_indices = get_active_voxel_indices(time_now)
            
            if all_active_voxel_indices.size > 0:
                # Filtering only dynamic voxels
                dynamic_voxel_indices_list = []
                for idx in all_active_voxel_indices:
                    if static_voxel_matrix[tuple(idx)] < STATIC_HIT_THRESHOLD:
                        dynamic_voxel_indices_list.append(idx)
                
                if dynamic_voxel_indices_list:
                    collected_frames.append(np.array(dynamic_voxel_indices_list))
            
            next_capture_time += interval

    serial_connection.close()
    print("\nData collection completed")

    if not collected_frames:
        print("ERROR: No data collected")
        return

    dataset = np.vstack(collected_frames)
    
    if dataset.shape[0] > 10000:
        print(f"Given data set ({dataset.shape[0]} points > 10000) is too big. It will take some time ")


    # Hyperparmeter Optimisation of DBSCAN (two methods)
    """
    ### Method A: k-Distance Graph (for eps) ###
    Function:
    1. Calculate the distance to the k-th nearest neighbor for each point (where k = MinPts)
    2. Plot these k-distances in ascending order
    3. Look for an "elbow" in the graph - a point where the curve starts to grow exponentially
    4. The eps value at this elbow is often a good choice
    """
    K_FOR_PLOT = 8 # NOTE: Same as DBSCAN_MIN_SAMPLES in main.py 
                   # Common heuristic formula: MinPts = 2 * num_features
                   # Our initial test showed that this value performs better
    
    print(f"\n### Method A: k-Distance Graph for k={K_FOR_PLOT}) ###")
    
    # k-Nearest Neighbors Algorithm (KNN) 
    nn = NearestNeighbors(n_neighbors=K_FOR_PLOT)
    nn.fit(dataset)
    distances, indices = nn.kneighbors(dataset)
    k_distances = np.sort(distances[:, K_FOR_PLOT - 1], axis=0)
    
    # Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(k_distances)
    plt.title(f'k-Distance Graph for k={K_FOR_PLOT}')
    plt.xlabel('Points sortet by distance')
    plt.ylabel(f'{K_FOR_PLOT}-nearest neighbor distance (optimal eps)')
    plt.grid(True)
    plt.savefig(f'k_distance_plot_k{K_FOR_PLOT}.png')
    print(f"Y-value at the elbow point is the optimal eps for min_samples={K_FOR_PLOT}")
    plt.show()


    """
    ### Method B: Automatic Grid Search with Silhouette Score (for best combination of hyperparameters for a model) ###
    Function:
    1. Making a grid consisting of different values for the hyperparameter
    2. Trying all possible combination of these values and evaluating your model with each combination
    3. Finding which combination gave the best performance using the silhouette score (measuring both how dis-/ similar a point is to its own/ other cluster)
    """
    print("\n### Method B: AutomaticGrid Search (Silhouette Score) ###")
    print("Searching for optimal parameter")

    # Search Space
    param_grid = {
        'eps': [1.0, 1.5, 2.0, 2.5, 3.0, 3.5], # Based on k-Distance Plot given elbow point
        'min_samples': [5, 8, 10, 12, 15]      # Testig around K_FOR_PLOT (= DBSCAN_MIN_SAMPLES)
    }

    best_score = -1 # Silhouette Value: [-1; 1]
    best_params = {}

    for params in ParameterGrid(param_grid):
        db = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])
        
        labels = db.fit_predict(dataset)
        
        unique_labels = set(labels) - {-1}
        if len(unique_labels) < 2:
            print(f"Parameter: {params}. Too few clusters available")
            continue
            
        score = silhouette_score(dataset, labels)
        print(f"Parameter: {params}| Score: {score:.4f}")
        
        if score > best_score:
            best_score = score
            best_params = params

    print("\n### Results ###")
    if best_score == -1:
        print("No valid Cluster Combination found")
    else:
        print(f"Best Score for Silhouette Method: {best_score:.4f}")
        print(f"Best Parameter:")
        print(f"DBSCAN_EPS = {best_params['eps']}")
        print(f"DBSCAN_MIN_SAMPLES = {best_params['min_samples']}")


if __name__ == "__main__":
    run_optimization()
